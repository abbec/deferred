% Deferred Shading
% Albert Cervin

# Introduction
Deferred shading is an old idea that was proposed by CITE in
1988. However, it has not been used extensively until recent
years. Today, deferred shading is de facto standard in game engines
and also in other types of real-time rendering. The need for deferred
shading arises in scenes with many dynamic light sources. In these
cases deferred shading can simplify and speed up lighting calculations
by order of magnitude. There are downsides however and the memory
bandwidth requirement of the algorithm is high, even with modern
graphics cards.

Deferred shading is also known under names such as deferred rendering
and deferred lighting. However, all three names essentially describes
the same algorithm.

# Method

## The G-buffer
Before any rendering happends, the scene contains geometric
information. In the classic rendering approach, called forward
rendering, each object is rendered and for each object, lighting
calculations are performed. The problem with this arises when there
are many dynamic light sources. The most common technique for this is
to use what is called über-shaders. Über shaders means that the
shaders are compiled in different permutations, one for each number of
dynamic light sources. This arises from the fact that it is not
possible to use a non-constant value in a shader loop. This kind of
loop is needed to sum all contributions from all lights for an
object. The problem with über-shaders are that the number of
permutations does not scale well. If the number of light sources is
increased, the number of shader permutations is increased
accordingly. This is not ideal.

Deferred shading tackles this problem by deferring the lighting
calculations to a later stage in the algorithm. This makes deferred
shading a multi-pass algorithm and means that the hardware has to
support multiple render targets (often referred to as MRT). The
multiple render targets are used for, in the first pass of the
algorithm, storing geometric scene information. The geometric
information is typically at least view space normals and depth.

This buffer (essentially a collection of render targets) is called a G-buffer and this stage of the algorithm is
called geometry stage. Vertex normals are transformed into view-space
by multiplying with a normal matrix that is the inverse transpose of
the upper 3x3 section of the matrix $world*view$.

\begin{equation}
	\text{vs\_normal} = \text{world\_view\_inv} * \text{vertex\_normal}
	\label{eq:vs_normals}
\end{equation}

To have sufficient precision in the normals for later calculations it
is possible to use 16-bit textures to store the normals. This is
however both wasteful and inefficient on modern hardware. The normals
can therefore be transformed into spheremap coordinates and then
stored in an 8-bit texture. CITE (check aras_p)

Depth can also be stored in the G-buffer. It is however possible to
use the already existing depth buffer generation and bind the depth
buffer as a shader resource in later stages. One important thing with
the depth buffer generated by hardware is that it contains projected
depth values, that is, clip space depth. To use this depth in
calculations it has to be unprojected by dividing it with the distance
to the far clip plane. 

The depth can furthermore be used to reconstruct view space positions
which means that the positions does not need to be stored in the G-buffer.

## The lighting stage
When all needed geometric information has been stored in the G-buffer
it can be used in the lighting stage. This is done by binding the
G-buffer render targets as shader resources.

The geometric information is then used in to calculate lighting in any
way that fits the application. Phong shading can for example be
implemented. Since the resources in the G-buffer are two-dimensional
textures, lighting calculations are done by drawing a full screen
triangle and point sampling the G-buffer textures.

At this stage it is easy to see that the number of lighting
calculations decreases. Consider a scene where there is $N$ light
sources and $M$ objects. With classic forward rendering, the
contribution from each light has to be calculated for each object
resulting in $N*M$ calculations. With the deferred approach, the $M$
objects are first rendered into the G-buffer and in the lighting
stage, one fullscreen triangle for each of the $N$ lights is
rendered. This means that the light calculation complexity of the
deferred shading algorithm is $N+M$.

## Implementation
The deferred shading algoritm has been implemented in the DirectX
SDK. The minimum required DirectX version is 10 which means that a
computer running at least Windows Vista is required to run the sample.

The implementation uses 16 bit textures (render targets) to achieve the maximum visual
quality. The normals X, Y and Z values are stored in R, G and B
channels of one render target, respectively.

Furthermore, the implementation stores depth in one 16 bit G-buffer
channel. This is a bit low resolution but this depth is used to
reconstruct view space position.

# Results
The result is an implementation of a deferred shading algorithm in the
DirectX SDK. The implementation runs in real-time and rendering
statistics for the algorithm are presented below.

# Discussion
The implementation works satisfying and it is efficient as
expected. To fully leverage all advantages of the algorithm, some
implementation of light scissoring is needed. Andersson CITE proposes
a solution to this problem by dividing the screen into tiles and
calculation which lights contribute to which tiles. This can be
implemented with the help of compute shaders, a feature available in
Direct X 11.

Deferred shading is also a very good platform for various
post-processing effect since there is already a texture resource
containing the image before post processing. If the time would have
allowed, I would have implemented some post processing effects.
